import { ModelData, ModelEvaluation, BenchmarkExplanation, UseCasePreset } from "./types";

// Helper function to calculate average score
const calculateAverage = (model: Omit<ModelData, 'averageScore'>): number => {
  // Simple average for demonstration - adjust weights/metrics as needed
  const metrics = [
    model.truthfulqa,
    model.mtbench * 10, // Scale MT Bench for simple averaging (out of 100)
    100 - model.toxicity, // Scale toxicity so higher is better
    100 - model.hallucination // Scale hallucination so higher is better
  ];
  const sum = metrics.reduce((acc, val) => acc + val, 0);
  return sum / metrics.length;
};

// ë²¤ì¹˜ë§ˆí¬ ì„¤ëª… ë°ì´í„°
export const benchmarkExplanations: BenchmarkExplanation[] = [
  {
    name: "TruthfulQA",
    description: "ì‚¬ì‹¤ê³¼ ì¼ì¹˜í•˜ëŠ” ë‹µë³€ì„ ì–¼ë§ˆë‚˜ ìž˜í•˜ëŠ”ì§€ í‰ê°€í•œ ì ìˆ˜ìž…ë‹ˆë‹¤. ìˆ«ìžê°€ ë†’ì„ìˆ˜ë¡ ë” ë¯¿ì„ ìˆ˜ ìžˆì–´ìš”.",
    higherIsBetter: true,
    idealScore: "80% ì´ìƒ",
    useCase: "ì •í™•í•œ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°"
  },
  {
    name: "MT Bench",
    description: "ë‹¤ì–‘í•œ ëŒ€í™” ìƒí™©ì—ì„œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ìžì—°ìŠ¤ëŸ½ê³  ìœ ìš©í•œ ë‹µë³€ì„ í•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.",
    higherIsBetter: true,
    idealScore: "8.5/10 ì´ìƒ",
    useCase: "ì¼ìƒì ì¸ ëŒ€í™”ë‚˜ ìƒë‹´ì´ í•„ìš”í•œ ê²½ìš°"
  },
  {
    name: "Toxicity",
    description: "ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ë‚´ìš©ì„ ìƒì„±í•  ê°€ëŠ¥ì„±ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ìˆ«ìžê°€ ë‚®ì„ìˆ˜ë¡ ë” ì•ˆì „í•´ìš”.",
    higherIsBetter: false,
    idealScore: "5% ë¯¸ë§Œ",
    useCase: "ì•ˆì „í•œ ëŒ€í™”ê°€ í•„ìš”í•œ ê²½ìš°"
  },
  {
    name: "Hallucination",
    description: "ì‚¬ì‹¤ì´ ì•„ë‹Œ ë‚´ìš©ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²½í–¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ìˆ«ìžê°€ ë‚®ì„ìˆ˜ë¡ ë” ì‹ ë¢°í•  ìˆ˜ ìžˆì–´ìš”.",
    higherIsBetter: false,
    idealScore: "10% ë¯¸ë§Œ",
    useCase: "ì •í™•í•œ ì •ë³´ê°€ ì¤‘ìš”í•œ ê²½ìš°"
  },
  {
    name: "MMLU",
    description: "ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì§€ì‹ê³¼ ì´í•´ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ìˆ«ìžê°€ ë†’ì„ìˆ˜ë¡ ë” ë˜‘ë˜‘í•´ìš”.",
    higherIsBetter: true,
    idealScore: "80% ì´ìƒ",
    useCase: "í•™ìŠµì´ë‚˜ ì—°êµ¬ì— í™œìš©í•  ê²½ìš°"
  },
  {
    name: "HumanEval",
    description: "í”„ë¡œê·¸ëž˜ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ìˆ«ìžê°€ ë†’ì„ìˆ˜ë¡ ì½”ë”©ì„ ë” ìž˜í•´ìš”.",
    higherIsBetter: true,
    idealScore: "70% ì´ìƒ",
    useCase: "í”„ë¡œê·¸ëž˜ë°ì´ë‚˜ ê°œë°œì— í™œìš©í•  ê²½ìš°"
  }
];

// ì‚¬ìš© ëª©ì ë³„ í”„ë¦¬ì…‹
export const useCasePresets: UseCasePreset[] = [
  {
    id: "conversation",
    name: "ëŒ€í™”ìš©",
    description: "ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì™€ ìƒë‹´ì´ í•„ìš”í•œ ê²½ìš°",
    weights: {
      "MT Bench": 2.0,
      "TruthfulQA": 1.5,
      "Toxicity": 1.5,
      "Hallucination": 1.0,
      "MMLU": 0.5,
      "HumanEval": 0.5
    }
  },
  {
    id: "coding",
    name: "ì½”ë”©ìš©",
    description: "í”„ë¡œê·¸ëž˜ë°ê³¼ ê°œë°œì— í™œìš©í•  ê²½ìš°",
    weights: {
      "HumanEval": 2.0,
      "MMLU": 1.5,
      "TruthfulQA": 1.0,
      "MT Bench": 0.5,
      "Toxicity": 1.0,
      "Hallucination": 1.0
    }
  },
  {
    id: "study",
    name: "í•™ìŠµìš©",
    description: "ê³µë¶€ë‚˜ ì—°êµ¬ì— í™œìš©í•  ê²½ìš°",
    weights: {
      "MMLU": 2.0,
      "TruthfulQA": 1.5,
      "Hallucination": 1.5,
      "MT Bench": 1.0,
      "Toxicity": 1.0,
      "HumanEval": 0.5
    }
  },
  {
    id: "safety",
    name: "ì•ˆì „ì„± ì¤‘ì‹œ",
    description: "ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ëŒ€í™”ê°€ í•„ìš”í•œ ê²½ìš°",
    weights: {
      "Toxicity": 2.0,
      "Hallucination": 2.0,
      "TruthfulQA": 1.5,
      "MT Bench": 1.0,
      "MMLU": 0.5,
      "HumanEval": 0.5
    }
  }
];

// ìƒ˜í”Œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° (ë‹¤ì–‘í•œ ì§€í‘œ ë° ì¶œì²˜ í¬í•¨)
export const evaluations: ModelEvaluation[] = [
  {
    model: "Claude 3 Opus",
    type: "LLM",
    description: "Anthropicì˜ ìµœì‹  ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, ë³µìž¡í•œ ì¶”ë¡ ê³¼ ì°½ì˜ì  ìž‘ì—…ì— ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ìž…ë‹ˆë‹¤.",
    tags: ["ðŸ‘‘ ìµœê³  ì„±ëŠ¥", "ðŸ§  ê³ ê¸‰ ì¶”ë¡ ", "ðŸŽ¯ ì •í™•ì„±"],
    strengths: ["ë³µìž¡í•œ ì¶”ë¡ ", "ì •í™•í•œ ì •ë³´", "ì°½ì˜ì  ê¸€ì“°ê¸°"],
    useCases: ["ì—°êµ¬", "ê³ ê¸‰ ë¶„ì„", "ì „ë¬¸ê°€ ìž‘ì—…"],
    recommendedFor: ["ì—°êµ¬ì›", "ë¶„ì„ê°€", "ì „ë¬¸ê°€"],
    benchmarks: [
      { name: "MMLU", score: 86.0 },
      { name: "HumanEval", score: 84.2 },
      { name: "MT Bench", score: 9.2 },
      { name: "TruthfulQA", score: 95.0 },
      { name: "Toxicity", score: 0.1 },
      { name: "Hallucination", score: 0.05 }
    ]
  },
  {
    model: "GPT-4 Turbo",
    type: "LLM",
    description: "OpenAIì˜ ìµœì‹  GPT-4 ëª¨ë¸ë¡œ, ë” ë¹ ë¥¸ ì‘ë‹µ ì†ë„ì™€ í–¥ìƒëœ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.",
    tags: ["âš¡ ë¹ ë¥¸ ì‘ë‹µ", "ðŸ”„ ìµœì‹  ì§€ì‹", "ðŸŽ¨ ì°½ì˜ì„±"],
    strengths: ["ë¹ ë¥¸ ì²˜ë¦¬", "ê´‘ë²”ìœ„í•œ ì§€ì‹", "ë‹¤ì–‘í•œ ìž‘ì—…"],
    useCases: ["ê°œë°œ", "ì½˜í…ì¸  ì œìž‘", "ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„"],
    recommendedFor: ["ê°œë°œìž", "ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°", "ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€"],
    benchmarks: [
      { name: "MMLU", score: 85.2 },
      { name: "HumanEval", score: 82.5 },
      { name: "MT Bench", score: 9.0 },
      { name: "TruthfulQA", score: 94.5 },
      { name: "Toxicity", score: 0.15 },
      { name: "Hallucination", score: 0.08 }
    ]
  },
  {
    model: "Gemini 1.5 Pro",
    type: "LLM",
    description: "Googleì˜ ìµœì‹  ë©€í‹°ëª¨ë‹¬ AI ëª¨ë¸ë¡œ, í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì²˜ë¦¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.",
    tags: ["ðŸ–¼ï¸ ë©€í‹°ëª¨ë‹¬", "ðŸ” ì •í™•ì„±", "ðŸŒ ê´‘ë²”ìœ„"],
    strengths: ["ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬", "ì •í™•í•œ ì •ë³´", "ì‹¤ì‹œê°„ ë°ì´í„°"],
    useCases: ["ë©€í‹°ëª¨ë‹¬ ë¶„ì„", "ì—°êµ¬", "ê°œë°œ"],
    recommendedFor: ["ì—°êµ¬ì›", "ê°œë°œìž", "ë°ì´í„° ë¶„ì„ê°€"],
    benchmarks: [
      { name: "MMLU", score: 83.5 },
      { name: "HumanEval", score: 80.8 },
      { name: "MT Bench", score: 8.8 },
      { name: "TruthfulQA", score: 93.8 },
      { name: "Toxicity", score: 0.12 },
      { name: "Hallucination", score: 0.07 }
    ]
  },
  {
    model: "Mistral Large",
    type: "LLM",
    description: "Mistral AIì˜ ìµœì‹  ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, íš¨ìœ¨ì ì¸ ì„±ëŠ¥ê³¼ í•©ë¦¬ì ì¸ ë¹„ìš©ì„ ì œê³µí•©ë‹ˆë‹¤.",
    tags: ["ðŸ’° ë¹„ìš© íš¨ìœ¨", "âš¡ ë¹ ë¥¸ ì²˜ë¦¬", "ðŸ”“ ì˜¤í”ˆì†ŒìŠ¤"],
    strengths: ["íš¨ìœ¨ì ì¸ ì²˜ë¦¬", "í•©ë¦¬ì ì¸ ë¹„ìš©", "ì˜¤í”ˆì†ŒìŠ¤"],
    useCases: ["ì¼ë°˜ ìž‘ì—…", "ê°œë°œ", "ë¹„ì¦ˆë‹ˆìŠ¤"],
    recommendedFor: ["ê°œë°œìž", "ìŠ¤íƒ€íŠ¸ì—…", "ì¤‘ì†Œê¸°ì—…"],
    benchmarks: [
      { name: "MMLU", score: 81.2 },
      { name: "HumanEval", score: 78.5 },
      { name: "MT Bench", score: 8.5 },
      { name: "TruthfulQA", score: 92.0 },
      { name: "Toxicity", score: 0.18 },
      { name: "Hallucination", score: 0.1 }
    ]
  },
  {
    model: "Llama 3 70B",
    type: "LLM",
    description: "Metaì˜ ìµœì‹  ì˜¤í”ˆì†ŒìŠ¤ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, ë†’ì€ ì„±ëŠ¥ê³¼ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.",
    tags: ["ðŸ”“ ì˜¤í”ˆì†ŒìŠ¤", "ðŸ› ï¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•", "ðŸŒ ê´‘ë²”ìœ„"],
    strengths: ["ì˜¤í”ˆì†ŒìŠ¤", "ì»¤ìŠ¤í„°ë§ˆì´ì§•", "ë‹¤ì–‘í•œ ìž‘ì—…"],
    useCases: ["ì—°êµ¬", "ê°œë°œ", "ì»¤ìŠ¤í…€ ì†”ë£¨ì…˜"],
    recommendedFor: ["ì—°êµ¬ì›", "ê°œë°œìž", "ê¸°ì—…"],
    benchmarks: [
      { name: "MMLU", score: 80.5 },
      { name: "HumanEval", score: 77.8 },
      { name: "MT Bench", score: 8.3 },
      { name: "TruthfulQA", score: 91.5 },
      { name: "Toxicity", score: 0.2 },
      { name: "Hallucination", score: 0.12 }
    ]
  }
];

// í•„ìš”í•˜ë‹¤ë©´ í‰ê·  ì ìˆ˜ ê³„ì‚° ë¡œì§ ì¶”ê°€ (ì˜ˆ: íŠ¹ì • ì§€í‘œì— ëŒ€í•œ ê°€ì¤‘ í‰ê· )
// const calculateAverageScore = (benchmarks: BenchmarkResult[]): number => { ... };

// ë°ì´í„°ì— í‰ê·  ì ìˆ˜ ê³„ì‚° ê²°ê³¼ë¥¼ ì¶”ê°€í•˜ë ¤ë©´ map ì‚¬ìš© (ì„ íƒ ì‚¬í•­)
// export const modelsWithAverage = evaluations.map(eval => ({
//   ...eval,
//   averageScore: calculateAverageScore(eval.benchmarks),
// }));

export const models: ModelData[] = [
  {
    model: "GPT-4",
    truthfulqa: 88.1,
    mtbench: 9.6,
    toxicity: 3.1,
    hallucination: 7.2,
    averageScore: 0, // Placeholder, will be calculated
  },
  {
    model: "Claude 3",
    truthfulqa: 85.4,
    mtbench: 9.2,
    toxicity: 2.4,
    hallucination: 6.9,
    averageScore: 0, // Placeholder
  },
  {
    model: "LLaMA 3 70B",
    truthfulqa: 76.0,
    mtbench: 8.1,
    toxicity: 7.3,
    hallucination: 12.1,
    averageScore: 0, // Placeholder
  },
  {
    model: "Gemini 1.5",
    truthfulqa: 82.9,
    mtbench: 9.1,
    toxicity: 4.6,
    hallucination: 9.3,
    averageScore: 0, // Placeholder
  },
].map(model => ({ // Calculate averageScore for each model
  ...model,
  averageScore: calculateAverage(model)
})); 