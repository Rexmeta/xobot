import { ModelData, ModelEvaluation, BenchmarkExplanation, UseCasePreset } from "./types";

// Helper function to calculate average score
const calculateAverage = (model: Omit<ModelData, 'averageScore'>): number => {
  // Simple average for demonstration - adjust weights/metrics as needed
  const metrics = [
    model.truthfulqa,
    model.mtbench * 10, // Scale MT Bench for simple averaging (out of 100)
    100 - model.toxicity, // Scale toxicity so higher is better
    100 - model.hallucination // Scale hallucination so higher is better
  ];
  const sum = metrics.reduce((acc, val) => acc + val, 0);
  return sum / metrics.length;
};

// ë²¤ì¹˜ë§ˆí¬ ì„¤ëª… ë°ì´í„°
export const benchmarkExplanations: BenchmarkExplanation[] = [
  {
    name: "TruthfulQA",
    description: "ì‚¬ì‹¤ê³¼ ì¼ì¹˜í•˜ëŠ” ë‹µë³€ì„ ì–¼ë§ˆë‚˜ ìž˜í•˜ëŠ”ì§€ í‰ê°€í•œ ì ìˆ˜ìž…ë‹ˆë‹¤. ìˆ«ìžê°€ ë†’ì„ìˆ˜ë¡ ë” ë¯¿ì„ ìˆ˜ ìžˆì–´ìš”.",
    higherIsBetter: true,
    idealScore: "80% ì´ìƒ",
    useCase: "ì •í™•í•œ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°"
  },
  {
    name: "MT Bench",
    description: "ë‹¤ì–‘í•œ ëŒ€í™” ìƒí™©ì—ì„œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ìžì—°ìŠ¤ëŸ½ê³  ìœ ìš©í•œ ë‹µë³€ì„ í•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.",
    higherIsBetter: true,
    idealScore: "8.5/10 ì´ìƒ",
    useCase: "ì¼ìƒì ì¸ ëŒ€í™”ë‚˜ ìƒë‹´ì´ í•„ìš”í•œ ê²½ìš°"
  },
  {
    name: "Toxicity",
    description: "ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ë‚´ìš©ì„ ìƒì„±í•  ê°€ëŠ¥ì„±ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ìˆ«ìžê°€ ë‚®ì„ìˆ˜ë¡ ë” ì•ˆì „í•´ìš”.",
    higherIsBetter: false,
    idealScore: "5% ë¯¸ë§Œ",
    useCase: "ì•ˆì „í•œ ëŒ€í™”ê°€ í•„ìš”í•œ ê²½ìš°"
  },
  {
    name: "Hallucination",
    description: "ì‚¬ì‹¤ì´ ì•„ë‹Œ ë‚´ìš©ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²½í–¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ìˆ«ìžê°€ ë‚®ì„ìˆ˜ë¡ ë” ì‹ ë¢°í•  ìˆ˜ ìžˆì–´ìš”.",
    higherIsBetter: false,
    idealScore: "10% ë¯¸ë§Œ",
    useCase: "ì •í™•í•œ ì •ë³´ê°€ ì¤‘ìš”í•œ ê²½ìš°"
  },
  {
    name: "MMLU",
    description: "ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì§€ì‹ê³¼ ì´í•´ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ìˆ«ìžê°€ ë†’ì„ìˆ˜ë¡ ë” ë˜‘ë˜‘í•´ìš”.",
    higherIsBetter: true,
    idealScore: "80% ì´ìƒ",
    useCase: "í•™ìŠµì´ë‚˜ ì—°êµ¬ì— í™œìš©í•  ê²½ìš°"
  },
  {
    name: "HumanEval",
    description: "í”„ë¡œê·¸ëž˜ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ìˆ«ìžê°€ ë†’ì„ìˆ˜ë¡ ì½”ë”©ì„ ë” ìž˜í•´ìš”.",
    higherIsBetter: true,
    idealScore: "70% ì´ìƒ",
    useCase: "í”„ë¡œê·¸ëž˜ë°ì´ë‚˜ ê°œë°œì— í™œìš©í•  ê²½ìš°"
  }
];

// ì‚¬ìš© ëª©ì ë³„ í”„ë¦¬ì…‹
export const useCasePresets: UseCasePreset[] = [
  {
    id: "conversation",
    name: "ëŒ€í™”ìš©",
    description: "ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì™€ ìƒë‹´ì´ í•„ìš”í•œ ê²½ìš°",
    weights: {
      "MT Bench": 2.0,
      "TruthfulQA": 1.5,
      "Toxicity": 1.5,
      "Hallucination": 1.0,
      "MMLU": 0.5,
      "HumanEval": 0.5
    }
  },
  {
    id: "coding",
    name: "ì½”ë”©ìš©",
    description: "í”„ë¡œê·¸ëž˜ë°ê³¼ ê°œë°œì— í™œìš©í•  ê²½ìš°",
    weights: {
      "HumanEval": 2.0,
      "MMLU": 1.5,
      "TruthfulQA": 1.0,
      "MT Bench": 0.5,
      "Toxicity": 1.0,
      "Hallucination": 1.0
    }
  },
  {
    id: "study",
    name: "í•™ìŠµìš©",
    description: "ê³µë¶€ë‚˜ ì—°êµ¬ì— í™œìš©í•  ê²½ìš°",
    weights: {
      "MMLU": 2.0,
      "TruthfulQA": 1.5,
      "Hallucination": 1.5,
      "MT Bench": 1.0,
      "Toxicity": 1.0,
      "HumanEval": 0.5
    }
  },
  {
    id: "safety",
    name: "ì•ˆì „ì„± ì¤‘ì‹œ",
    description: "ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ëŒ€í™”ê°€ í•„ìš”í•œ ê²½ìš°",
    weights: {
      "Toxicity": 2.0,
      "Hallucination": 2.0,
      "TruthfulQA": 1.5,
      "MT Bench": 1.0,
      "MMLU": 0.5,
      "HumanEval": 0.5
    }
  }
];

// ìƒ˜í”Œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° (ë‹¤ì–‘í•œ ì§€í‘œ ë° ì¶œì²˜ í¬í•¨)
export const evaluations: ModelEvaluation[] = [
  {
    model: "GPT-4",
    type: "LLM",
    description: "ê°€ìž¥ ê°•ë ¥í•˜ê³  ë‹¤ìž¬ë‹¤ëŠ¥í•œ AI ëª¨ë¸ìž…ë‹ˆë‹¤. ë³µìž¡í•œ ë¬¸ì œ í•´ê²°ê³¼ ì°½ì˜ì ì¸ ìž‘ì—…ì— ë›°ì–´ë‚©ë‹ˆë‹¤.",
    tags: ["ðŸŽ¯ ê³ ì •ë°€", "ðŸ”’ ì•ˆì „ì„± ìš°ìˆ˜", "ðŸ’¡ ì°½ì˜ì "],
    strengths: ["ë³µìž¡í•œ ë¬¸ì œ í•´ê²°", "ì°½ì˜ì ì¸ ê¸€ì“°ê¸°", "ì •í™•í•œ ì •ë³´ ì œê³µ"],
    useCases: ["ì—°êµ¬", "ê°œë°œ", "ì°½ìž‘"],
    recommendedFor: ["ì „ë¬¸ê°€", "ê°œë°œìž", "ì—°êµ¬ìž"],
    benchmarks: [
      { name: "TruthfulQA", score: 88.1, unit: "%", source: "Paper" },
      { name: "MT Bench", score: 9.6, unit: "/10", source: "LMSYS Arena" },
      { name: "Toxicity", score: 3.1, unit: "%", source: "Perspective API" },
      { name: "Hallucination", score: 7.2, unit: "%", source: "OpenCompass" },
      { name: "MMLU", score: 86.4, source: "OpenAI Eval" },
      { name: "HumanEval", score: 67.0, source: "OpenAI Eval" },
    ],
  },
  {
    model: "Claude 3 Opus",
    type: "LLM",
    description: "ë¶€ë“œëŸ½ê³  ì •ì§í•œ ëŒ€í™”ê°€ íŠ¹ì§•ì¸ AI ëª¨ë¸ìž…ë‹ˆë‹¤. ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.",
    tags: ["ðŸ§˜ ë¶€ë“œëŸ¬ì›€", "ðŸ¤ ì‹ ë¢°ì„±", "ðŸ“š í•™ìŠµ ë„ìš°ë¯¸"],
    strengths: ["ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”", "ì•ˆì „í•œ ìƒë‹´", "í•™ìŠµ ì§€ì›"],
    useCases: ["êµìœ¡", "ìƒë‹´", "ì¼ìƒ ëŒ€í™”"],
    recommendedFor: ["í•™ìƒ", "êµì‚¬", "ì¼ë°˜ ì‚¬ìš©ìž"],
    benchmarks: [
      { name: "TruthfulQA", score: 85.4, unit: "%", source: "Anthropic Eval" },
      { name: "MT Bench", score: 9.2, unit: "/10", source: "LMSYS Arena" },
      { name: "Toxicity", score: 2.4, unit: "%", source: "Anthropic Eval" },
      { name: "Hallucination", score: 6.9, unit: "%", source: "OpenCompass" },
      { name: "MMLU", score: 86.8, source: "Anthropic Eval" },
      { name: "HumanEval", score: 80.0, source: "Anthropic Eval" },
    ],
  },
  {
    model: "LLaMA 3 70B",
    type: "LLM",
    description: "ì˜¤í”ˆì†ŒìŠ¤ ê¸°ë°˜ì˜ ê°•ë ¥í•œ AI ëª¨ë¸ìž…ë‹ˆë‹¤. ì»¤ìŠ¤í„°ë§ˆì´ì§•ì´ ê°€ëŠ¥í•˜ê³  ë‹¤ì–‘í•œ ìš©ë„ë¡œ í™œìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.",
    tags: ["ðŸ”“ ì˜¤í”ˆì†ŒìŠ¤", "ðŸ› ï¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•", "ðŸ’ª ê°•ë ¥í•œ ì„±ëŠ¥"],
    strengths: ["ì»¤ìŠ¤í„°ë§ˆì´ì§•", "ì˜¤í”ˆì†ŒìŠ¤ í™œìš©", "ë‹¤ì–‘í•œ ìš©ë„"],
    useCases: ["ê°œë°œ", "ì—°êµ¬", "ì»¤ìŠ¤í…€ ì†”ë£¨ì…˜"],
    recommendedFor: ["ê°œë°œìž", "ì—°êµ¬ìž", "ê¸°ì—…"],
    benchmarks: [
      { name: "TruthfulQA", score: 76.0, unit: "%", source: "Meta Eval" },
      { name: "MT Bench", score: 8.1, unit: "/10", source: "LMSYS Arena" },
      { name: "Toxicity", score: 7.3, unit: "%", source: "Meta Eval" },
      { name: "Hallucination", score: 12.1, unit: "%", source: "OpenCompass" },
      { name: "MMLU", score: 81.7, source: "Meta Eval" },
      { name: "HumanEval", score: 62.2, source: "Meta Eval" },
    ],
  },
  {
    model: "Gemini 1.5 Pro",
    type: "LLM",
    description: "êµ¬ê¸€ì˜ ìµœì‹  AI ëª¨ë¸ë¡œ, ë¹ ë¥¸ ì‘ë‹µê³¼ ì •í™•í•œ ì •ë³´ ì œê³µì´ íŠ¹ì§•ìž…ë‹ˆë‹¤.",
    tags: ["âš¡ ë¹ ë¥¸ ì‘ë‹µ", "ðŸŽ¯ ì •í™•ì„±", "ðŸŒ ë‹¤êµ­ì–´ ì§€ì›"],
    strengths: ["ë¹ ë¥¸ ì‘ë‹µ", "ì •í™•í•œ ì •ë³´", "ë‹¤êµ­ì–´ ì§€ì›"],
    useCases: ["ê²€ìƒ‰", "ë²ˆì—­", "ì •ë³´ ì œê³µ"],
    recommendedFor: ["ì¼ë°˜ ì‚¬ìš©ìž", "ë¹„ì¦ˆë‹ˆìŠ¤", "ê¸€ë¡œë²Œ ì‚¬ìš©ìž"],
    benchmarks: [
      { name: "TruthfulQA", score: 82.9, unit: "%", source: "Google Eval" },
      { name: "MT Bench", score: 9.1, unit: "/10", source: "LMSYS Arena" },
      { name: "Toxicity", score: 4.6, unit: "%", source: "Google Eval" },
      { name: "Hallucination", score: 9.3, unit: "%", source: "OpenCompass" },
      { name: "MMLU", score: 83.7, source: "Google Eval" },
      { name: "HumanEval", score: 58.4, source: "Google Eval" },
    ],
  },
];

// í•„ìš”í•˜ë‹¤ë©´ í‰ê·  ì ìˆ˜ ê³„ì‚° ë¡œì§ ì¶”ê°€ (ì˜ˆ: íŠ¹ì • ì§€í‘œì— ëŒ€í•œ ê°€ì¤‘ í‰ê· )
// const calculateAverageScore = (benchmarks: BenchmarkResult[]): number => { ... };

// ë°ì´í„°ì— í‰ê·  ì ìˆ˜ ê³„ì‚° ê²°ê³¼ë¥¼ ì¶”ê°€í•˜ë ¤ë©´ map ì‚¬ìš© (ì„ íƒ ì‚¬í•­)
// export const modelsWithAverage = evaluations.map(eval => ({
//   ...eval,
//   averageScore: calculateAverageScore(eval.benchmarks),
// }));

export const models: ModelData[] = [
  {
    model: "GPT-4",
    truthfulqa: 88.1,
    mtbench: 9.6,
    toxicity: 3.1,
    hallucination: 7.2,
    averageScore: 0, // Placeholder, will be calculated
  },
  {
    model: "Claude 3",
    truthfulqa: 85.4,
    mtbench: 9.2,
    toxicity: 2.4,
    hallucination: 6.9,
    averageScore: 0, // Placeholder
  },
  {
    model: "LLaMA 3 70B",
    truthfulqa: 76.0,
    mtbench: 8.1,
    toxicity: 7.3,
    hallucination: 12.1,
    averageScore: 0, // Placeholder
  },
  {
    model: "Gemini 1.5",
    truthfulqa: 82.9,
    mtbench: 9.1,
    toxicity: 4.6,
    hallucination: 9.3,
    averageScore: 0, // Placeholder
  },
].map(model => ({ // Calculate averageScore for each model
  ...model,
  averageScore: calculateAverage(model)
})); 